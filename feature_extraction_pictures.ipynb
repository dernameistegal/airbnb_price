{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/airbnb_price/blob/main/feature_extraction_pictures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title remove repos from disc\n",
        "%cd /content\n",
        "!rm -r airbnb_price"
      ],
      "metadata": {
        "id": "QdOQljNz3blJ",
        "outputId": "7a641c4f-c3df-4a62-d3fb-cbc884bb4bbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7o4vsf3Sn9",
        "cellView": "form",
        "outputId": "f5e8d51c-1494-4d3a-bd87-837151209119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Clone repo\n",
        "!git clone https://github.com/dernameistegal/airbnb_price.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'airbnb_price'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 44 (delta 14), reused 23 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add paths to library search path\n",
        "import sys \n",
        "\n",
        "sys.path.append(\"/content/airbnb_price/custom_functions\")\n",
        "sys.path.append(\"/content/airbnb_price/feature_extraction\")"
      ],
      "metadata": {
        "id": "JwAoaaJGkz3k",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CxkNtPCI8nl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7682e9c9-5d38-4c0c-a70e-e04944b247ff"
      },
      "source": [
        "#@title Imports and drive\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# own modules\n",
        "import general_utils as gu\n",
        "import feature_extraction_utils as fu\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#@title Mount drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5FPlKWBJMWs",
        "outputId": "20345ff9-36b6-420a-990d-29de0c8387ae",
        "cellView": "form"
      },
      "source": [
        "#@title define device\n",
        "\n",
        "# device\n",
        "device = gu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla T4\n",
            "2 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate channelwise moments of pictures\n",
        "hostpics_dir = \"/content/drive/MyDrive/Colab/rbnb/data/hostpics\"\n",
        "\n",
        "means, stds = fu.calculate_channelwise_moments(hostpics_dir)"
      ],
      "metadata": {
        "id": "CDh453I7b9T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data_paths = os.listdir(hostpics_dir)\n",
        "x = np.load(hostpics_dir + \"/\" + data_paths[34])"
      ],
      "metadata": {
        "id": "3Y7K5YovdU2H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x)"
      ],
      "metadata": {
        "id": "j62VSQqTdiig",
        "outputId": "20022a36-db40-4966-8dce-69e5d5b213b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc277a42410>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title make dataset\n",
        "\n",
        "\n",
        "# initialize dataset and dataloader\n",
        "dataset = fu.Dataset(hostpics_dir, means, stds, 10)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# get pretrained model\n",
        "vgg = torchvision.models.vgg19(pretrained=True)\n",
        "feature_extractor = vgg.features[0:31]\n",
        "\n",
        "# compute features for later training\n",
        "x = fu.compute_train_features(device, dataloader, feature_extractor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p5h86a3dtPir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "5369a79f-5bdb-4cb6-c7fd-92fc3c248df6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-88df49b16338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# compute features for later training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_train_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/airbnb_price/feature_extraction/feature_extraction_utils.py\u001b[0m in \u001b[0;36mcompute_train_features\u001b[0;34m(device, dataloader, feature_extractor, output_dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"pointnet2_2\" # model to be trained\n",
        "model = importlib.import_module(model_name)\n",
        "destination_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\"\n",
        "destination_path = destination_path + model_name"
      ],
      "metadata": {
        "id": "G7D9JJgB_thB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pretrained model? If yes run this chunk\n",
        "source_path = \"/content/drive/MyDrive/Colab/tree_learning/trained_models/PartSeg1\"  # pretrained model to be used (check for compatibility with model to be trained)\n",
        "source_path = source_path + \"/.\"\n",
        "!rm -r $destination_path\n",
        "!mkdir $destination_path\n",
        "!cp -a $source_path $destination_path"
      ],
      "metadata": {
        "id": "2JdT2VVH-eSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train and val split to be used in dataloaders\n",
        "gu.gen_split(percentages=[0.7, 0.3])"
      ],
      "metadata": {
        "id": "0lqq14Xto5DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "!python train_partseg.py --model $model_name --log_dir $model_name --npoint 8192 --epoch 30 --step_size 30 --batch_size 8 --weight 1"
      ],
      "metadata": {
        "id": "a0rLC8NaKO5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model? If yes run this chunk\n",
        "source_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\"\n",
        "source_path = source_path + model_name\n",
        "source_path = source_path + \"/.\"\n",
        "destination_path = \"/content/drive/MyDrive/Colab/tree_learning/trained_models/test/test/\" # destination path to save trained model and corresponding files\n",
        "\n",
        "!mkdir -p $destination_path\n",
        "!cp -a $source_path $destination_path"
      ],
      "metadata": {
        "id": "DSFO4IrX-m54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot performance\n",
        "# plot loss and accuracy against epochs\n",
        "    \n",
        "loss_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/loss.npy\"\n",
        "pu.plot(\"Loss\", \"Loss\", loss_path, yscale='linear')\n",
        "\n",
        "accs_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/accs.npy\"\n",
        "pu.plot(\"Accuracy\", \"Accuracy\", accs_path, yscale='linear')\n",
        "\n",
        "w_accs_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/w_accs.npy\"\n",
        "pu.plot(\"weighted Accuracy\", \"weighted Accuracy\", w_accs_path, yscale='linear')\n",
        "\n",
        "w_accs_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/tree_accs.npy\"\n",
        "pu.plot(\"tree Accuracy\", \"tree Accuracy\", w_accs_path, yscale='linear')\n",
        "\n",
        "w_accs_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/no_tree_accs.npy\"\n",
        "pu.plot(\"no tree Accuracy\", \"no tree Accuracy\", w_accs_path, yscale='linear')\n",
        "\n",
        "mious_path = w_accs_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/performance/mious.npy\"\n",
        "pu.plot(\"miou\", \"miou\", mious_path, yscale='linear')"
      ],
      "metadata": {
        "id": "WK66PhjOCbFS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis"
      ],
      "metadata": {
        "id": "0VAlV-EU-GXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title definition of visual analysis function\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def explore2(points, prediction, label, mode=\"pointcloud\", colormode=\"binary\"):\n",
        "\n",
        "    # explore results with pointcloud\n",
        "    if mode == \"pointcloud\":\n",
        "        if colormode == \"binary\":\n",
        "            prediction[np.logical_and(label == 1, prediction == 1)] = 4  # true positive\n",
        "            prediction[np.logical_and(label == 1, prediction == 0)] = 2  # false negative\n",
        "            prediction[np.logical_and(label == 0, prediction == 1)] = 3  # false positive\n",
        "            prediction[np.logical_and(label == 0, prediction == 0)] = 1  # true negative\n",
        "        \n",
        "        df = pd.DataFrame(data=np.column_stack((points, label, prediction)), columns=[\"x\", \"y\", \"z\", \"label\", \"prediction\"])\n",
        "        # create vector of sizes (two sizes for tree and non-tree points)\n",
        "        size = df.iloc[:, -2] * 0.02 + 1\n",
        "\n",
        "        fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
        "                            color='prediction',\n",
        "                            symbol='label', size=size, opacity=0, size_max=5)\n",
        "\n",
        "        # tight layout\n",
        "        fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "    # explore results with histogram\n",
        "    if mode == \"histogram\":\n",
        "        tp = sum(np.logical_and(label == 1, prediction >= 0.5))\n",
        "        fn = sum(np.logical_and(label == 1, prediction <= 0.5))\n",
        "        fp = sum(np.logical_and(label == 0, prediction >= 0.5))\n",
        "        tn = sum(np.logical_and(label == 0, prediction <= 0.5))\n",
        "        print(f\"{tp / len(label)*100:.2f} are true positive\")  # true positive\n",
        "        print(f\"{fn / len(label)*100:.2f} are false negative\")  # false negative\n",
        "        print(f\"{fp / len(label)*100:.2f} are false positive\")  # false positive\n",
        "        print(f\"{tn / len(label)*100:.2f} are true negative\")  # true negative\n",
        "        iou_tree = tp / (tp + fp + fn)\n",
        "        iou_not_tree = tn / (tn + fn + fp)\n",
        "        acc_tree, acc_not_tree = tp / (tp + fn), tn / (tn + fp)\n",
        "        w_acc = (acc_tree + acc_not_tree) / 2\n",
        "        print(f\"the iou_tree is {iou_tree:.4f} the iou_not_tree is {iou_not_tree:.4f}\")\n",
        "        print(f\"the miou is {(iou_tree + iou_not_tree) / 2:.4f}\")\n",
        "        print(f\"the acc_tree is {acc_tree:.4f} the acc_not_tree is {acc_not_tree:.4f}\")\n",
        "        print(f\"the weighted accuracy is {w_acc:.4f}\")\n",
        "        \n",
        "        fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "        axs[0].hist(prediction)\n",
        "        axs[1].hist(label)\n",
        "        fig.show()"
      ],
      "metadata": {
        "id": "iRDCif1ysVAG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treenumber = 15\n",
        "npoints = 2048\n",
        "split_path = \"/content/Pointnet_Pointnet2_pytorch/data/\" + \"valsplit.npy\"\n",
        "# um einen bestimmten Baum zu wählen, die folgende Zeile ausführen\n",
        "#gu.gen_split(paths = [split_path], shuffle=False, percentages=[1])"
      ],
      "metadata": {
        "id": "PDD1NuMJauSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title generate predictions for chosen tree from trained model (saved in result)\n",
        "\n",
        "# load learned model\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "\n",
        "classifier = model.get_model(2, normal_channel=False).to(device)\n",
        "classifier.apply(inplace_relu)\n",
        "\n",
        "model_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\" + model_name + \"/checkpoints/best_model.pth\"\n",
        "checkpoint = torch.load(model_path)\n",
        "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# instantiate dataset (choose from trainsplit, valsplit or nosplit)\n",
        "root = \"/content/Pointnet_Pointnet2_pytorch/data/\"\n",
        "\n",
        "\n",
        "testtransform = t.Compose([t.Normalize()])\n",
        "TRAIN_DATASET = dset.PartNormalDataset(root=root, \n",
        "                                  npoints=npoints,\n",
        "                                  transform=testtransform,\n",
        "                                  splitpath=split_path, \n",
        "                                  normal_channel=False, mode=\"eval\")\n",
        "\n",
        "# predict targets for arbitrary tree number\n",
        "points, label, target, _, upoints = TRAIN_DATASET[treenumber]\n",
        "points, label, target = torch.tensor(points), torch.tensor(label), torch.tensor(target)\n",
        "points, target = torch.unsqueeze(points, 0), torch.unsqueeze(target, 0)\n",
        "points, label, target = points.float().to(device), label.long().to(device), target.long().to(device)\n",
        "points = points.transpose(2, 1)\n",
        "\n",
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
        "    if (y.is_cuda):\n",
        "        return new_y.cuda()\n",
        "    return new_y\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    classifier.eval()\n",
        "    result = classifier(points, to_categorical(label, 1))[0]\n",
        "\n",
        "\n",
        "preds = torch.argmax(result[0], axis=1)\n",
        "points = points[0].T\n",
        "target = target[0]\n",
        "points = points[:, :3]\n",
        "points = points.detach().cpu().numpy()\n",
        "preds = preds.detach().cpu().numpy()\n",
        "target = target.detach().cpu().numpy()\n",
        "m = torch.nn.Softmax()\n",
        "pred_probabilities = m(result[0])[:,1].detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "kpLffSEKfBXC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Numerical Analysis for the chosen tree\n",
        "correct = np.sum(preds == target)\n",
        "print(\"Accuracy\", correct / (npoints))\n",
        "# confusion values in numbers and histograms of predicted probabilities and true labels\n",
        "explore2(upoints, pred_probabilities, target, mode=\"histogram\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2xqMBVl_99rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot binary predictions (yellow = true positive, red = false positive, blue = true negative, purple = false negative)\n",
        "explore2(upoints, preds, target, mode=\"pointcloud\", colormode=\"binary\")"
      ],
      "metadata": {
        "id": "3lsfCI3I2mAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non-binary predictions\n",
        "explore2(upoints, pred_probabilities, np.array(target), mode=\"pointcloud\")"
      ],
      "metadata": {
        "id": "6uQe2auQeVNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}