{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/airbnb_price/blob/main/models/pictures_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Preparation"
      ],
      "metadata": {
        "id": "jbtdvB6FQgvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title remove repos from disc\n",
        "%cd /content\n",
        "!rm -r airbnb_price"
      ],
      "metadata": {
        "id": "QdOQljNz3blJ",
        "outputId": "d3eac349-668c-4f88-9501-7a698caf7ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7o4vsf3Sn9",
        "cellView": "form",
        "outputId": "d626b504-2e42-47d2-8fc9-6fb6fc083ae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Clone repo\n",
        "!git clone https://github.com/dernameistegal/airbnb_price.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'airbnb_price'...\n",
            "remote: Enumerating objects: 311, done.\u001b[K\n",
            "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
            "remote: Compressing objects: 100% (290/290), done.\u001b[K\n",
            "remote: Total 311 (delta 150), reused 92 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (311/311), 2.69 MiB | 8.28 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add paths to library search path\n",
        "import sys \n",
        "\n",
        "sys.path.append(\"/content/airbnb_price/custom_functions\")"
      ],
      "metadata": {
        "id": "JwAoaaJGkz3k",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CxkNtPCI8nl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8f65e9-9828-41b3-8bad-d1018c47c26d"
      },
      "source": [
        "#@title Imports and drive\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# own modules\n",
        "import general_utils as gu\n",
        "import picture_model_utils as pu\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#@title Mount drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5FPlKWBJMWs",
        "outputId": "8812f295-0ddf-40ce-f9c3-89233073dfdd",
        "cellView": "form"
      },
      "source": [
        "#@title define device\n",
        "\n",
        "# device\n",
        "device = gu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla P100-PCIE-16GB\n",
            "4 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Model thumbnail pictures"
      ],
      "metadata": {
        "id": "rmwXb1Kb46Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thumbnails_dir = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_raw\"\n",
        "response_dir = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_response\""
      ],
      "metadata": {
        "id": "rsbXtkQz4_uP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make train_dataset and val_dataset and respective dataloader with thumbnails\n",
        "\n",
        "# load moments\n",
        "thumbnails_moments = np.load(\"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_moments.npy\")\n",
        "thumbnails_moments = torch.from_numpy(thumbnails_moments)\n",
        "\n",
        "# initialize dataset and dataloader\n",
        "dataset = pu.Dataset(picture_dir=thumbnails_dir, response_dir = response_dir, channel_moments=thumbnails_moments, ndata=11000)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [8000, 3000], generator=torch.Generator().manual_seed(42))\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "PIqyQ8V28UMd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate root mse to get reference value for model performance\n",
        "logprice = []\n",
        "for i in tqdm(range(len(val_dataset))):\n",
        "    logprice.append(val_dataset[i][1])"
      ],
      "metadata": {
        "id": "GgGq0tpD4pIy",
        "outputId": "3b1dc5ed-92da-4cf6-e116-59694e1866ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:21<00:00, 139.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_logprice = np.mean(logprice)\n",
        "squared_error = (np.array(logprice) - mean_logprice) ** 2\n",
        "mean_squared_error = np.mean(squared_error)\n",
        "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
        "root_mean_squared_error"
      ],
      "metadata": {
        "id": "gpUKnFVB6sC9",
        "outputId": "9d7d17b8-1fd5-4108-f111-ef3662e0276f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.66298217"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define models classes\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, feature_extractor, finalizer):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.finalizer = finalizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.finalizer(x)\n",
        "    \n",
        "        return x\n",
        "\n",
        "class Finalizer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(512)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.linear1 = torch.nn.Linear(in_features = 25088, out_features=4096)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(4096)\n",
        "        self.drop1 = torch.nn.Dropout()\n",
        "        self.linear2 = torch.nn.Linear(in_features=4096, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.bn4(F.relu(self.linear1(x)))\n",
        "        x = self.drop1(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "id": "-9RGDHyeNXfm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define feature extractor\n",
        "vgg = torchvision.models.vgg19(pretrained=True)\n",
        "feature_extractor = vgg.features[0:31]"
      ],
      "metadata": {
        "id": "XcP_tLZ7O5cS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define finalizer\n",
        "finalizer = Finalizer()"
      ],
      "metadata": {
        "id": "FDfsVTSfVPJw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Model(feature_extractor=feature_extractor, finalizer=finalizer)"
      ],
      "metadata": {
        "id": "ODLjvltkVWEz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "lSsgmS6NvdV-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze parameters in feature extractor\n",
        "# for name, p in model.named_parameters():\n",
        "#     if \"feature_extractor\" in name:\n",
        "#         p.requires_grad = False"
      ],
      "metadata": {
        "id": "v_chLc92WAe9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "AfT5rNA7YLDs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define train functions\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, StepLR\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastprogress\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "    \n",
        "def train(dataloader, optimizer, model, loss_fn, device, master_bar, scaler):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "        \n",
        "        image, target = image.to(device), target.to(device)\n",
        "\n",
        "        # zero gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(image)\n",
        "        prediction = torch.squeeze(prediction)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward() #loss.backward()\n",
        "        scaler.step(optimizer) # optimizer.step()\n",
        "        scaler.update()\n",
        "\n",
        "        # For plotting the train loss, save it for each sample\n",
        "        epoch_loss.append(np.sqrt(loss.item()))\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn, device, master_bar):\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "            \n",
        "            image, target = image.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            prediction = model.forward(image)\n",
        "            prediction = torch.squeeze(prediction)\n",
        "\n",
        "            # loss calculation\n",
        "            loss = loss_fn(prediction, target)\n",
        "\n",
        "            # For plotting the train loss, save it for each sample\n",
        "            epoch_loss.append(np.sqrt(loss.item()))\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "    \n",
        "\n",
        "def run_training(model, optimizer, loss_fn, device, num_epochs,\n",
        "                 train_dataloader, val_dataloader, verbose=False):\n",
        "  \n",
        "    # technical stuff\n",
        "    start_time = time.time()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "\n",
        "    # instantiate losses\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in master_bar:\n",
        "\n",
        "        # Train the model\n",
        "        epoch_train_loss = train(train_dataloader, optimizer, model, loss_fn, device, master_bar, scaler)\n",
        "        #Validate the model\n",
        "        epoch_val_loss = validate(val_dataloader, model, loss_fn, device, master_bar)\n",
        "\n",
        "        # Save loss and acc for plotting\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        val_loss.append(epoch_val_loss)\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            master_bar.write(\n",
        "                f'Train root mse: {epoch_train_loss:.4f}, val root mse: {epoch_val_loss:.4f}')\n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return train_loss, val_loss\n",
        "    "
      ],
      "metadata": {
        "cellView": "code",
        "id": "EXv7vzLvXghr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, target = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "Bs29EC19QIyn"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(torch.permute(image[5], (1, 2 ,0)))"
      ],
      "metadata": {
        "id": "1yfX4L9vQUOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss = run_training(model=model, optimizer=optimizer, loss_fn=loss_fn, device=device, num_epochs=100,\n",
        "                                    train_dataloader=train_dataloader, val_dataloader=val_dataloader, verbose=True)"
      ],
      "metadata": {
        "id": "WLE_PzsPaVyx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}