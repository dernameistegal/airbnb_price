{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auswertung05_01_22.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonaden94/treelearning/blob/main/current_work/Visual%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visual Exploration with trained models"
      ],
      "metadata": {
        "id": "diVS06lcyB7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone repo\n",
        "key = \\\n",
        "\"\"\"\n",
        "-----BEGIN RSA PRIVATE KEY-----\n",
        "MIIJKAIBAAKCAgEAvcWKSRCU6cnVThYINDBAWLj0eAP3Z4jS+kMK/TW1Yb3KcjRM\n",
        "x9BUHB8fTnL6SagNyScU0vzwl+jOROSOP6sUsl67Cq1YKEqdJHhY7/0oB6kZdo2N\n",
        "sip75TT6dUjH31Ht5uSzfV8713MyhhITb9YtmPoPxrGJ9XzTMOYS2n97H08ibxTs\n",
        "vGn6xGK8HELEQqRk9xdsBM2fA0dADLqXmoaYvs3S0ktTl6H92C77eSUv2iH45SRI\n",
        "DDvcEmi4wEvw7ae2SzSYNLiwVOcP98wL2VztvRgdqVCI+9z0GTvaRD78dy1pz/DV\n",
        "fexSYc9Jt/ZhSvyVwBNOCKEiaX4BPfheIkFadWBpJ1OpxbPANPVPTwcdR02hXlPm\n",
        "DuMeX91o2Rc2JJZnWt9OxakYIwOQclDKg1WSTA3fC7eAoKQfEd9oc4lwmSjAVr78\n",
        "si9K4wziKqVPZI4Z3kZ5E4POz/CvRFnzYrWhm4QRTq6kmltKb4mCWHKTmYen5dOF\n",
        "zzJqSJjuTfJtL8qD2U1XUlEFq+7Gcx43TpxnL8ir393UJH6eYsKtz5t6fvE2CcGe\n",
        "GekSTKckw8QHkR/yF01RWlEjGTVtSmy2ZY7ifkp9VUyHzshUntsRAXMZ1bJsglRA\n",
        "z6L/hTOi2wwiPCzKCdbIs7OB98PciE3ZTdVJC+fn7KkNjhkt6JxqQgkANzkCAwEA\n",
        "AQKCAgEAikgGcyVFDXKIHwVI5xZ93OixIz7oqaX27mup90aKq/VLLprTlApHL9Kx\n",
        "0k1P+hoeKYRz1SaA/oCixWqyCMzWIP+MVcRoZ7uu9CNJ015qK+LZbhzJspjofOV0\n",
        "17+3/Q/LRiNCc0nQ5jbICw/i3+x2f3E/y64U9DAICCqudE7OXcshMUZTFxw2oaG8\n",
        "pu8z6ce21qJXkMxwYUgq8NuKmwwXA3ohdCF1gRmGSmA52FXzn4R/xCEC6v83Zqau\n",
        "cVkk71f1KqnhexFVVBim9w7VV4cyqUaIXpcTqkugBz8o1e/7sbAC2YYJW1+3zBPr\n",
        "CMTcsnKJgFPQ2dLoq2wo5Yo0tctfaMRezhpLquIYJlg190IN53aTPvIExBj+N+DW\n",
        "Tg4WfSLoYH/zD7/o3mr8yW2n3RhD6D0GJH1NkwP0mlpA2QprYpR0F5QZQAi1R5KA\n",
        "6kAgWkgJD7duSkLGSurtTENgMv+dXhu7ZB2iPioiGcx548gu9iXLuJMe/C4wiwlt\n",
        "HbiY4qRHLffoCY/u/VCraTJY+6iW0Xu0VUwe2QBrXJsuSX1kWdkpADyfjkPyr6o/\n",
        "AbOqpxMjyqDKEIXd9jyfeUTKN8IyFHvLP3eTshUAKqA6CAA4h1NPkvz1bLLsMRG3\n",
        "E6mziKRen5+I1EIZPOHhipmsXBxtiPzo8l45R2UjmaIFWLBn3Y0CggEBAOxPCiNn\n",
        "geoATBABfklCWkydO9ac4956eFDp0ZDRU2rQ/9uzRPeQ92VmaRvYxO9Ijqmhu80J\n",
        "nYCs/1XVeUkxMXwcJhrSeSNMQ20urWJTDCdJMCm1tZxIbsFaAipA9a/H6HXZBP3Y\n",
        "IOY/G5Th4WIPbG41mMqGqwWogYNZ6frtax1kp8SJNcDqvTXgIIbs2zgo9sOrKom9\n",
        "3i54fuwJ+loWzgKj6yd5eGif9gzuCGVpO+RpXOvrQppytjVOQr9CU9Z8OJPF5QAS\n",
        "vmuluqrKVrCD8gx3mEHJIhhoixoNfJbrti+D49gByKBsI6UtlfnKL/RR4WYxuLLQ\n",
        "rplsrVJfEJawS9MCggEBAM2VxEJn8bTWX8MICF/zdXwVTABO4GYGvCX40HJ0WIaT\n",
        "t0O5RFOrbamQt8Umm13h6UIs9DVEh2UKhgjLBwNq5tNY65mP+TZAVVug33gpHDyI\n",
        "lIHNLxQQYFTUd4FrFW95vpX7bx5tqpCEMic+gfp+9ruHHq/6s3ccfBq6/1e8hQ39\n",
        "lgJq9odoPj1BuSMTSgZ/foHnEA+oLnDCsg+8wFWYQGBC3sj5qP5IqpP7J0bbpQRT\n",
        "M+eA69YyUvVIj1QapP9yFslxYjpPef8FD6llveQdIvxZpqMYykG6TzDU/5dAmYN2\n",
        "JetY8dhyg96e7R85aIyNcg8ReQG3iHzDeT1NLJSRxUMCggEAeAJwEKjphnBeMKbB\n",
        "fu0OtOgJUqXc58jkv5rvjg9wwMehmO8DMINT0RBggv7kjO0ZXra/jJK8hXPWPL4s\n",
        "WWp9Sh11kJuhX7bEa3eQIGYyvuTha91XfSYf8VwHy3OwEnSA7xCnA0+27ZfRJxxL\n",
        "/SP+Gj5n+TrJMhdwpseMF55pjsTmmt5gCThtnSXU/xDdCDltkNOlx8xAQPN66d7r\n",
        "YMNCHn8m1qZO6zuJlulwJCh8fTSxNzMEYTGurYWwSjeiIkR16z5OXWongL3q/f/C\n",
        "ZOStkX1POuGtyh2Vv0ZoJrFQlfLyTGojfK1OsP1ktDXlgrvur5rCxTVL5qkVoMac\n",
        "wxqHdwKCAQAjRYrCieriR9VuNLabH74MZ+r+Moo1dvpY2XOJ74Qwsq9Co0qhwEu0\n",
        "R+v/mzwUw2mtvOC5MuS35TJR1+OAJpsrr5ncYuMy956tddBhYUxC5nv0OSvWmWit\n",
        "pTZLsf+ffJfCS70oz0/wM34XVZYfUCEs02Xkc3LPAMgaHfMpLmL1n4hZKdjaKnxj\n",
        "Lh+BcRHGQ6GE0AvlY8lz9zNtl8i35sNEwLRQbuUbm4QIl5KJia2qLEw/b9MGkOPC\n",
        "yYwttdSRLxXRwe5EatZXdprVSWtm88jI2ujIGry4wipMCn8/iAnOkDq5Qi1cIWmW\n",
        "jFXKgaL6WlozU6AbN03nefIXHmKDqu7ZAoIBAGiIJOk7o4VeEB5xP8PXqrZofHBB\n",
        "47rBlaH2ajtSBSTip31e++3iIBmZvvKu2lLEQXKny+1cJgCbl0ICTducoB6r7ARL\n",
        "U4xbotNgQIyKsMn9rQttqzHVYpbwe1j/eWok5DuRkBuc3Nlcl4B3nPsLD1GKB/QM\n",
        "x/rPv4T8Accr5czgzNZEJfkuI4/9za5gA3ltS90+kJU1IszZxMseuxc7yLEsjAi5\n",
        "2y301P1rqMdQ7xg6JXCjh3yPxQ0ug2ZykFh1X9+DwG86Belqlh56W/nFl298IkTG\n",
        "KIVWo9C9mDm8hm0TGim2KOKNP5rkj7ndETB1S57qi+1amSaGXOcBbLAGzuQ=\n",
        "-----END RSA PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "!mkdir -p /root/.ssh\n",
        "with open(r'/root/.ssh/id_rsa', 'w', encoding=\"utf8\") as fh:\n",
        "    fh.write(key)\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!chmod 644 /root/.ssh/known_hosts\n",
        "!chmod 600 /root/.ssh/id_rsa\n",
        "!ssh -T git@github.com\n",
        "!git clone git@github.com:jonaden94/treelearning.git\n",
        "!git clone https://github.com/dernameistegal/Pointnet_Pointnet2_pytorch.git"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PykMFb-EyaMc",
        "outputId": "5d7a4210-bd8d-4518-bbc4-c74ce783bc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-babeld-b6e6da7b\n",
            "# github.com:22 SSH-2.0-babeld-b6e6da7b\n",
            "# github.com:22 SSH-2.0-babeld-b6e6da7b\n",
            "Hi jonaden94/treelearning! You've successfully authenticated, but GitHub does not provide shell access.\n",
            "fatal: destination path 'treelearning' already exists and is not an empty directory.\n",
            "fatal: destination path 'Pointnet_Pointnet2_pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title switch directory\n",
        "# switch directory since we do everything from there\n",
        "%cd Pointnet_Pointnet2_pytorch/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "treSrul-PadH",
        "outputId": "64af2cf4-36f4-4077-d348-93845adf769a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Pointnet_Pointnet2_pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add paths to library search path\n",
        "import sys \n",
        "\n",
        "sys.path.append(\"/content/Pointnet_Pointnet2_pytorch/data_utils\")\n",
        "sys.path.append(\"/content/treelearning/python\")\n",
        "sys.path.append(\"/content/Pointnet_Pointnet2_pytorch/custom_functions\")"
      ],
      "metadata": {
        "id": "kjeYoObqysoD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and drive\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "import data_utils as du\n",
        "import plot_utils as pu\n",
        "import transform as t\n",
        "import general_utils as gu\n",
        "import ShapeNetDataLoader as dset\n",
        "import importlib\n",
        "\n",
        "from google.colab import drive\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gBLh7E2xyvQ0",
        "outputId": "693c6c42-5849-4ca2-9fcd-b7b1759b9e64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define device\n",
        "device = gu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1AoIW64MPvog",
        "outputId": "f9d77f5b-02e1-4259-f4a9-e5ac21bb26ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla K80\n",
            "2 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get chunks from drive? If yes run this chunk\n",
        "!ln -s /content/drive/MyDrive/Colab/tree_learning/01234 /content/Pointnet_Pointnet2_pytorch/data"
      ],
      "metadata": {
        "id": "mAnqRKFxM8_c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make dataset\n",
        "\n",
        "# data paths\n",
        "forest_path = \"/content/drive/MyDrive/Colab/tree_learning/data/forest_labeled_clean.npy\"\n",
        "position_path = \"/content/drive/MyDrive/Colab/tree_learning/data/positions_relevant.npy\"\n",
        "chunk_path = \"/content/Pointnet_Pointnet2_pytorch/data/01234/\"\n",
        "!mkdir /content/Pointnet_Pointnet2_pytorch/data/01234\n",
        "\n",
        "if not os.listdir(chunk_path):\n",
        "    dataset = du.TreeDataset(6.9, 5, forest_path, position_path, chunk_path=chunk_path, transform=None, new_chunks=True, voxel_size=0.05, remove999=True)\n",
        "else:\n",
        "    dataset = du.TreeDataset(6.9, 5, forest_path, position_path, chunk_path=chunk_path, transform=None, new_chunks=False, voxel_size=0.05, remove999=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lkGnMtHMzAAI",
        "outputId": "5f851a01-1557-42bf-d265-59a69060bb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/Pointnet_Pointnet2_pytorch/data/01234’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose model from drive\n",
        "source_path = \"/content/drive/MyDrive/Colab/tree_learning/trained_models/Acc9605_IOU8672\"  # pretrained model and corresponding files to be loaded\n",
        "model_name = set(os.listdir(source_path)) - set([\"pointnet2_utils.py\", \"logs\", \"checkpoints\", \"performance\", \"split\"])\n",
        "model_name = list(model_name)[0]\n",
        "model_name = model_name[0:-3]\n",
        "source_path = source_path + \"/.\"\n",
        "destination_path = \"/content/Pointnet_Pointnet2_pytorch/log/part_seg/\"\n",
        "destination_path = destination_path + model_name\n",
        "!rm -r $destination_path\n",
        "!mkdir $destination_path\n",
        "!cp -a $source_path $destination_path"
      ],
      "metadata": {
        "id": "XI444rqCxzEF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(destination_path)\n",
        "model = importlib.import_module(model_name)"
      ],
      "metadata": {
        "id": "GkF3eROiPNb2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Metrics"
      ],
      "metadata": {
        "id": "q2r1LRM4zpVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot performance\n",
        "# plot loss and accuracy against epochs\n",
        "loss_path = destination_path + \"/performance/loss.npy\"\n",
        "pu.plot(\"Loss\", \"Loss\", loss_path, yscale='linear')\n",
        "\n",
        "accs_path = destination_path + \"/performance/accs.npy\"\n",
        "pu.plot(\"Accuracy\", \"Accuracy\", accs_path, yscale='linear')\n",
        "\n",
        "w_accs_path = destination_path + \"/performance/w_accs.npy\"\n",
        "pu.plot(\"weighted Accuracy\", \"weighted Accuracy\", w_accs_path, yscale='linear')\n",
        "\n",
        "mious_path = destination_path + \"/performance/mious.npy\"\n",
        "pu.plot(\"miou\", \"miou\", mious_path, yscale='linear')"
      ],
      "metadata": {
        "id": "u-TcALpwysSO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual Predictions and further Evaluation"
      ],
      "metadata": {
        "id": "VV8nlhEeztB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title definition of visual analysis function\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def explore2(points, prediction, label, mode=\"pointcloud\", colormode=\"binary\"):\n",
        "\n",
        "    # explore results with pointcloud\n",
        "    if mode == \"pointcloud\":\n",
        "        if colormode == \"binary\":\n",
        "            prediction[np.logical_and(label == 1, prediction == 1)] = 4  # true positive\n",
        "            prediction[np.logical_and(label == 1, prediction == 0)] = 2  # false negative\n",
        "            prediction[np.logical_and(label == 0, prediction == 1)] = 3  # false positive\n",
        "            prediction[np.logical_and(label == 0, prediction == 0)] = 1  # true negative\n",
        "        \n",
        "        df = pd.DataFrame(data=np.column_stack((points, label, prediction)), columns=[\"x\", \"y\", \"z\", \"label\", \"prediction\"])\n",
        "        # create vector of sizes (two sizes for tree and non-tree points)\n",
        "        size = df.iloc[:, -2] * 0.02 + 1\n",
        "\n",
        "        fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
        "                            color='prediction',\n",
        "                            symbol='label', size=size, opacity=0, size_max=5)\n",
        "\n",
        "        # tight layout\n",
        "        fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "    # explore results with histogram\n",
        "    if mode == \"histogram\":\n",
        "        tp = sum(np.logical_and(label == 1, prediction >= 0.5))\n",
        "        fn = sum(np.logical_and(label == 1, prediction <= 0.5))\n",
        "        fp = sum(np.logical_and(label == 0, prediction >= 0.5))\n",
        "        tn = sum(np.logical_and(label == 0, prediction <= 0.5))\n",
        "        print(f\"{tp / len(label)*100:.2f} are true positive\")  # true positive\n",
        "        print(f\"{fn / len(label)*100:.2f} are false negative\")  # false negative\n",
        "        print(f\"{fp / len(label)*100:.2f} are false positive\")  # false positive\n",
        "        print(f\"{tn / len(label)*100:.2f} are true negative\")  # true negative\n",
        "        iou_tree = tp / (tp + fp + fn)\n",
        "        iou_not_tree = tn / (tn + fn + fp)\n",
        "        acc_tree, acc_not_tree = tp / (tp + fn), tn / (tn + fp)\n",
        "        w_acc = (acc_tree + acc_not_tree) / 2\n",
        "        print(f\"the iou_tree is {iou_tree:.4f} the iou_not_tree is {iou_not_tree:.4f}\")\n",
        "        print(f\"the miou is {(iou_tree + iou_not_tree) / 2:.4f}\")\n",
        "        print(f\"the acc_tree is {acc_tree:.4f} the acc_not_tree is {acc_not_tree:.4f}\")\n",
        "        print(f\"the weighted accuracy is {w_acc:.4f}\")\n",
        "        \n",
        "        fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "        axs[0].hist(prediction)\n",
        "        axs[1].hist(label)\n",
        "        fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UIEJ1V2IxkOB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treenumber = 1\n",
        "npoints = 5000\n",
        "split_path = destination_path + \"/split/valsplit.npy\"\n",
        "# um einen bestimmten Baum zu wählen, die folgende Zeile ausführen\n",
        "#gu.gen_split(paths = [split_path], shuffle=False, percentages=[1])"
      ],
      "metadata": {
        "id": "62BttJvvx_xH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title generate predictions for chosen tree from trained model (saved in result)\n",
        "\n",
        "# load learned model\n",
        "def inplace_relu(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('ReLU') != -1:\n",
        "        m.inplace=True\n",
        "\n",
        "classifier = model.get_model(2, normal_channel=False).to(device)\n",
        "classifier.apply(inplace_relu)\n",
        "\n",
        "model_path = destination_path + \"/checkpoints/best_model.pth\"\n",
        "checkpoint = torch.load(model_path)\n",
        "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# instantiate dataset (choose from trainsplit, valsplit or nosplit)\n",
        "root = \"/content/Pointnet_Pointnet2_pytorch/data/\"\n",
        "\n",
        "\n",
        "testtransform = t.Compose([t.Normalize()])\n",
        "TRAIN_DATASET = dset.PartNormalDataset(root=root, \n",
        "                                  npoints=npoints,\n",
        "                                  transform=testtransform,\n",
        "                                  splitpath=split_path, \n",
        "                                  normal_channel=False, mode=\"eval\")\n",
        "\n",
        "# predict targets for arbitrary tree number\n",
        "points, label, target, _, upoints = TRAIN_DATASET[treenumber]\n",
        "points, label, target = torch.tensor(points), torch.tensor(label), torch.tensor(target)\n",
        "points, target = torch.unsqueeze(points, 0), torch.unsqueeze(target, 0)\n",
        "points, label, target = points.float().to(device), label.long().to(device), target.long().to(device)\n",
        "points = points.transpose(2, 1)\n",
        "\n",
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
        "    if (y.is_cuda):\n",
        "        return new_y.cuda()\n",
        "    return new_y\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    classifier.eval()\n",
        "    result = classifier(points, to_categorical(label, 1))[0]\n",
        "\n",
        "\n",
        "preds = torch.argmax(result[0], axis=1)\n",
        "points = points[0].T\n",
        "target = target[0]\n",
        "points = points[:, :3]\n",
        "points = points.detach().cpu().numpy()\n",
        "preds = preds.detach().cpu().numpy()\n",
        "target = target.detach().cpu().numpy()\n",
        "m = torch.nn.Softmax()\n",
        "pred_probabilities = m(result[0])[:,1].detach().cpu().numpy()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TAtXNiigxkXg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Numerical Analysis for the chosen tree\n",
        "correct = np.sum(preds == target)\n",
        "print(\"Accuracy\", correct / (npoints))\n",
        "# confusion values in numbers and histograms of predicted probabilities and true labels\n",
        "explore2(upoints, pred_probabilities, target, mode=\"histogram\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1kdTOygUxkUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot binary predictions (yellow = true positive, red = false positive, blue = true negative, purple = false negative)\n",
        "explore2(upoints, np.array(preds), np.array(target), mode=\"pointcloud\", colormode=\"binary\")"
      ],
      "metadata": {
        "id": "6uQe2auQeVNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non-binary predictions\n",
        "explore2(upoints, pred_probabilities, np.array(target), mode=\"pointcloud\")"
      ],
      "metadata": {
        "id": "MyGSanbVivJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}