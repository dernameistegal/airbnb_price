{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/airbnb_price/blob/main/models/pictures_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Preparation"
      ],
      "metadata": {
        "id": "jbtdvB6FQgvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title remove repos from disc\n",
        "%cd /content\n",
        "!rm -r airbnb_price"
      ],
      "metadata": {
        "id": "QdOQljNz3blJ",
        "outputId": "aa656c96-69ab-4709-9815-27aca4249448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7o4vsf3Sn9",
        "cellView": "form",
        "outputId": "8b1b7fb2-427a-4542-bb5f-3de639e6bce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Clone repo\n",
        "!git clone https://github.com/dernameistegal/airbnb_price.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'airbnb_price'...\n",
            "remote: Enumerating objects: 509, done.\u001b[K\n",
            "remote: Counting objects: 100% (509/509), done.\u001b[K\n",
            "remote: Compressing objects: 100% (479/479), done.\u001b[K\n",
            "remote: Total 509 (delta 267), reused 139 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (509/509), 3.60 MiB | 9.18 MiB/s, done.\n",
            "Resolving deltas: 100% (267/267), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add paths to library search path\n",
        "import sys \n",
        "\n",
        "sys.path.append(\"/content/airbnb_price/custom_functions\")"
      ],
      "metadata": {
        "id": "JwAoaaJGkz3k",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CxkNtPCI8nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b1c6ef-2478-46cd-e23c-7cc8412b8bb9",
        "cellView": "form"
      },
      "source": [
        "#@title Imports and drive\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "# own modules\n",
        "import general_utils as gu\n",
        "import picture_model_utils as pu\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#@title Mount drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5FPlKWBJMWs",
        "outputId": "6dd86b5d-8254-46d0-f391-aca7ced0e9f8",
        "cellView": "form"
      },
      "source": [
        "#@title define device\n",
        "\n",
        "# device\n",
        "device = gu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla P100-PCIE-16GB\n",
            "4 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Model thumbnail pictures"
      ],
      "metadata": {
        "id": "rmwXb1Kb46Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define train, val split\n",
        "listings = pd.read_pickle(\"/content/drive/MyDrive/Colab/airbnb/data/data1/listings_workfile.pickle\")\n",
        "trainsplit, valsplit, _ = gu.train_val_test_split(listings.index)"
      ],
      "metadata": {
        "id": "UtXc3a88KDXf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# information regarding predictor and response\n",
        "thumbnail_dir = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_raw\"\n",
        "\n",
        "log_price = listings[\"log_price\"]\n",
        "log_price = log_price.to_dict()"
      ],
      "metadata": {
        "id": "-LpJcrINjJqW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make train_dataset and val_dataset and respective dataloader with thumbnails\n",
        "train_dataset = pu.ThumbnailsDataset(thumbnail_dir=thumbnail_dir, response=log_price, split=trainsplit)\n",
        "val_dataset = pu.ThumbnailsDataset(thumbnail_dir=thumbnail_dir, response=log_price, split=valsplit)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "PIqyQ8V28UMd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate root mse to get reference value for model performance\n",
        "logprice = []\n",
        "for i in tqdm(range(len(val_dataset))):\n",
        "    logprice.append(val_dataset[i][1])"
      ],
      "metadata": {
        "id": "GgGq0tpD4pIy",
        "outputId": "c7cd7128-baa0-45c7-b7b0-d77bea6fbe90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1711/1711 [00:06<00:00, 259.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_logprice = np.mean(logprice)\n",
        "squared_error = (np.array(logprice) - mean_logprice) ** 2\n",
        "mean_squared_error = np.mean(squared_error)\n",
        "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
        "root_mean_squared_error"
      ],
      "metadata": {
        "id": "gpUKnFVB6sC9",
        "outputId": "1890da41-a136-4da3-f67b-2effa785a343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.64899296"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define models classes\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, feature_extractor, finalizer):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.finalizer = finalizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.finalizer(x)\n",
        "    \n",
        "        return x\n",
        "\n",
        "class Finalizer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(512)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.drop1 = torch.nn.Dropout()\n",
        "        self.linear1 = torch.nn.Linear(in_features = 25088, out_features=256)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(256)\n",
        "        self.drop2 = torch.nn.Dropout()\n",
        "        self.linear2 = torch.nn.Linear(in_features=256, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.drop1(x)\n",
        "        x = self.bn4(F.relu(self.linear1(x)))\n",
        "        x = self.drop2(x)\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "id": "-9RGDHyeNXfm",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define train functions\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, StepLR\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastprogress\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "    \n",
        "def train(dataloader, optimizer, model, loss_fn, device, master_bar, scaler):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "        \n",
        "        image, target = image.to(device), target.to(device)\n",
        "        target = torch.squeeze(target)\n",
        "\n",
        "        # zero gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(image)\n",
        "        prediction = torch.squeeze(prediction)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward() #loss.backward()\n",
        "        scaler.step(optimizer) # optimizer.step()\n",
        "        scaler.update()\n",
        "\n",
        "        # For plotting the train loss, save it for each sample\n",
        "        epoch_loss.append(np.sqrt(loss.item()))\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn, device, master_bar):\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "            \n",
        "            image, target = image.to(device), target.to(device)\n",
        "            target = torch.squeeze(target)\n",
        "\n",
        "            # Forward pass\n",
        "            prediction = model.forward(image)\n",
        "            prediction = torch.squeeze(prediction)\n",
        "\n",
        "            # loss calculation\n",
        "            loss = loss_fn(prediction, target)\n",
        "\n",
        "            # For plotting the train loss, save it for each sample\n",
        "            epoch_loss.append(np.sqrt(loss.item()))\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "    \n",
        "\n",
        "def run_training(model, optimizer, scheduler, loss_fn, device, num_epochs,\n",
        "                 train_dataloader, val_dataloader, verbose, \n",
        "                 savefolder=\"training_results1\"):\n",
        "  \n",
        "    # make path to save performance measures and state dict\n",
        "    savepath = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_model/\" + savefolder\n",
        "    os.mkdir(savepath)\n",
        "  \n",
        "    # technical stuff\n",
        "    start_time = time.time()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "\n",
        "    # instantiate losses\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in master_bar:\n",
        "\n",
        "        # Train the model\n",
        "        epoch_train_loss = train(train_dataloader, optimizer, model, loss_fn, device, master_bar, scaler)\n",
        "        #Validate the model\n",
        "        epoch_val_loss = validate(val_dataloader, model, loss_fn, device, master_bar)\n",
        "\n",
        "        # update scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save loss and acc for plotting\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        val_loss.append(epoch_val_loss)\n",
        "\n",
        "        if val_loss[-1] <= np.min(val_loss):\n",
        "            torch.save(model.state_dict(), savepath + \"/checkpoint.pt\")\n",
        "            print(\"saving model...\")\n",
        "\n",
        "        if verbose:\n",
        "            master_bar.write(\n",
        "                f'Train root mse: {epoch_train_loss:.4f}, val root mse: {epoch_val_loss:.4f}')\n",
        "            \n",
        "    \n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return train_loss, val_loss\n",
        "    "
      ],
      "metadata": {
        "id": "EXv7vzLvXghr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define feature extractor\n",
        "vgg = torchvision.models.vgg19(pretrained=True)\n",
        "feature_extractor = vgg.features[0:31]\n",
        "\n",
        "# define finalizer\n",
        "finalizer = Finalizer()\n",
        "\n",
        "# define model\n",
        "model = Model(feature_extractor=feature_extractor, finalizer=finalizer)\n",
        "model = model.to(device)\n",
        "\n",
        "# freeze parameters in feature extractor\n",
        "# for name, p in model.named_parameters():\n",
        "#     if \"feature_extractor\" in name:\n",
        "#         p.requires_grad = False\n",
        "\n",
        "# print parameters that are optimized\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name)"
      ],
      "metadata": {
        "id": "fxTQlwraHN2A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.1 ** (epoch // 10), \n",
        "                                              last_epoch=- 1, verbose=True)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "6BBa0Vt7G8zC",
        "outputId": "a9c74cd3-796b-4638-bf7b-db4bedb679e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss = run_training(model=model, optimizer=optimizer, scheduler=scheduler, loss_fn=loss_fn, device=device, num_epochs=20,\n",
        "                                    train_dataloader=train_dataloader, val_dataloader=val_dataloader, verbose=True)"
      ],
      "metadata": {
        "id": "WLE_PzsPaVyx",
        "outputId": "cac2991f-72e1-4add-afb5-d5325048f888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      5.00% [1/20 01:53<35:53]\n",
              "    </div>\n",
              "    \n",
              "Train root mse: 3.9377, val root mse: 3.7342<p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='6' class='' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      9.52% [6/63 00:10<01:41]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 1.0000e-03.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys = []\n",
        "ypreds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    model = model.eval()\n",
        "\n",
        "    for x, y in tqdm(val_dataloader):\n",
        "        x = x.to(device)\n",
        "        y_pred = model(x)\n",
        "        y_pred = list(y_pred.data.cpu())\n",
        "        ypreds = ypreds + y_pred\n",
        "\n",
        "        ys = ys + list(y)"
      ],
      "metadata": {
        "id": "TD_11ZhW1-iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pearsonr(ys, ypreds))\n",
        "plt.scatter(ys, ypreds)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vSjF4FKr3ofM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gu.plot(\"Root-MSE during training\", \"Root-MSE\", train_loss, val_loss, yscale='linear', legend=[\"Training\", \"Validation\"],\n",
        "         thinning=1, save_path=None)\n"
      ],
      "metadata": {
        "id": "QQvTEWq_2t31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}