{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/airbnb_price/blob/main/pictures_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Preparation"
      ],
      "metadata": {
        "id": "jbtdvB6FQgvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title remove repos from disc\n",
        "%cd /content\n",
        "!rm -r airbnb_price"
      ],
      "metadata": {
        "id": "QdOQljNz3blJ",
        "outputId": "bc5b85ce-b0da-4cb7-ff60-c3f87b969a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ7o4vsf3Sn9",
        "cellView": "form",
        "outputId": "660deb84-4bd5-43fc-f560-d31dc87f7bc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Clone repo\n",
        "!git clone https://github.com/dernameistegal/airbnb_price.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'airbnb_price'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 136 (delta 62), reused 58 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (136/136), 1.90 MiB | 2.66 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title add paths to library search path\n",
        "import sys \n",
        "\n",
        "sys.path.append(\"/content/airbnb_price/custom_functions\")\n",
        "sys.path.append(\"/content/airbnb_price/feature_extraction\")"
      ],
      "metadata": {
        "id": "JwAoaaJGkz3k",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CxkNtPCI8nl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b0e64e-ea97-4ac7-e7ab-c8d53b05b977"
      },
      "source": [
        "#@title Imports and drive\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# own modules\n",
        "import general_utils as gu\n",
        "import feature_extraction_utils as fu\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "#@title Mount drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5FPlKWBJMWs",
        "outputId": "83d27b2a-bd95-41cf-e421-dac453c67a30",
        "cellView": "form"
      },
      "source": [
        "#@title define device\n",
        "\n",
        "# device\n",
        "device = gu.get_device()\n",
        "num_cpus = os.cpu_count()\n",
        "print(num_cpus, 'CPUs available')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available: True ; cudnn available: True ; num devices: 1\n",
            "Using device Tesla T4\n",
            "2 CPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Cleaning Hostpics (Dont has to be run again)"
      ],
      "metadata": {
        "id": "QLS2yRBCQb6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hostpics_dir = \"/content/drive/MyDrive/Colab/airbnb/data/hostpics/hostpics_raw\""
      ],
      "metadata": {
        "id": "jqlGUnqDjabS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make dataset and dataloader with hostpics\n",
        "\n",
        "# load moments\n",
        "hostpics_moments = np.load(\"/content/drive/MyDrive/Colab/airbnb/data/hostpics/hostpics_moments.npy\")\n",
        "hostpics_moments = torch.from_numpy(hostpics_moments)\n",
        "\n",
        "# initialize dataset and dataloader\n",
        "dataset = fu.Dataset(filepath=hostpics_dir, channel_moments=hostpic_moments, ndata=10)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "p5h86a3dtPir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features from pretrained model\n",
        "vgg = torchvision.models.vgg19(pretrained=True)\n",
        "feature_extractor = vgg.features[0:31]\n",
        "\n",
        "# compute features for later training\n",
        "train_features = fu.compute_train_features(device=device, dataloader=dataloader, feature_extractor=feature_extractor)\n",
        "train_features = train.features.cpu().numpy()"
      ],
      "metadata": {
        "id": "OJiY3_a68RwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model thumbnail pictures"
      ],
      "metadata": {
        "id": "rmwXb1Kb46Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thumbnails_dir = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_raw\"\n",
        "response_dir = \"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_response\""
      ],
      "metadata": {
        "id": "rsbXtkQz4_uP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make train_dataset and val_dataset and respective dataloader with thumbnails\n",
        "\n",
        "# load moments\n",
        "thumbnails_moments = np.load(\"/content/drive/MyDrive/Colab/airbnb/data/thumbnails/thumbnails_moments.npy\")\n",
        "thumbnails_moments = torch.from_numpy(thumbnails_moments)\n",
        "\n",
        "# initialize dataset and dataloader\n",
        "dataset = fu.Dataset(picture_dir=thumbnails_dir, response_dir= response_dir, channel_moments=thumbnails_moments, ndata=1000)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [700, 300], generator=torch.Generator().manual_seed(42))\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "PIqyQ8V28UMd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define models classes\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, feature_extractor, finalizer):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.finalizer = finalizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.finalizer(x)\n",
        "    \n",
        "        return x\n",
        "\n",
        "class Finalizer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(512)\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(512)\n",
        "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.linear1 = torch.nn.Linear(in_features = 25088, out_features=4096)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(4096)\n",
        "        self.drop1 = torch.nn.Dropout()\n",
        "        self.linear2 = torch.nn.Linear(in_features=4096, out_features=2048)\n",
        "        self.drop2 = torch.nn.Dropout()\n",
        "        self.linear3 = torch.nn.Linear(in_features=2048, out_features=1024)\n",
        "        self.drop3 = torch.nn.Dropout()\n",
        "        self.linear4 = torch.nn.Linear(in_features=1024, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.bn4(F.relu(self.linear1(x)))\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.drop2(x)\n",
        "        x = F.relu(self.linear3(x))\n",
        "        x = self.drop3(x)\n",
        "        x = self.linear4(x)\n",
        "\n",
        "        return x\n",
        "        "
      ],
      "metadata": {
        "cellView": "form",
        "id": "-9RGDHyeNXfm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define feature extractor\n",
        "vgg = torchvision.models.vgg19(pretrained=True)\n",
        "feature_extractor = vgg.features[0:31]"
      ],
      "metadata": {
        "id": "XcP_tLZ7O5cS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define finalizer\n",
        "finalizer = Finalizer()"
      ],
      "metadata": {
        "id": "FDfsVTSfVPJw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Model(feature_extractor=feature_extractor, finalizer=finalizer)"
      ],
      "metadata": {
        "id": "ODLjvltkVWEz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "lSsgmS6NvdV-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze parameters in feature extractor\n",
        "for name, p in model.named_parameters():\n",
        "    if \"feature_extractor\" in name:\n",
        "        p.requires_grad = False"
      ],
      "metadata": {
        "id": "v_chLc92WAe9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "AfT5rNA7YLDs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title define train functions\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, StepLR\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastprogress\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "    \n",
        "def train(dataloader, optimizer, model, loss_fn, device, master_bar, scaler):\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "        \n",
        "        image, target = image.to(device), target.to(device)\n",
        "\n",
        "        # zero gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(image)\n",
        "        prediction = torch.squeeze(prediction)\n",
        "\n",
        "        # loss calculation\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward() #loss.backward()\n",
        "        scaler.step(optimizer) # optimizer.step()\n",
        "        scaler.update()\n",
        "\n",
        "        # For plotting the train loss, save it for each sample\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "    print(\"prediction:\", prediction)\n",
        "    print(\"target:\", target)\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn, device, master_bar):\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, target in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "            \n",
        "            image, target = image.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            prediction = model.forward(image)\n",
        "            prediction = torch.squeeze(prediction)\n",
        "\n",
        "            # loss calculation\n",
        "            loss = loss_fn(prediction, target)\n",
        "\n",
        "            # For plotting the train loss, save it for each sample\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "    \n",
        "\n",
        "def run_training(model, optimizer, loss_fn, device, num_epochs,\n",
        "                 train_dataloader, val_dataloader, verbose=False):\n",
        "  \n",
        "    # technical stuff\n",
        "    start_time = time.time()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "\n",
        "    # instantiate losses\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    for epoch in master_bar:\n",
        "\n",
        "        # Train the model\n",
        "        epoch_train_loss = train(train_dataloader, optimizer, model, loss_fn, device, master_bar, scaler)\n",
        "        #Validate the model\n",
        "        epoch_val_loss = validate(val_dataloader, model, loss_fn, device, master_bar)\n",
        "\n",
        "        # Save loss and acc for plotting\n",
        "        train_loss.append(epoch_train_loss)\n",
        "        val_loss.append(epoch_val_loss)\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            master_bar.write(\n",
        "                f'Train loss: {epoch_train_loss:.2f}, val loss: {epoch_val_loss:.2f}')\n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def plot(title, label, train_results, val_results, yscale='linear', save_path=None, \n",
        "         extra_pt=None, extra_pt_label=None):\n",
        "    \"\"\"Plot learning curves.\n",
        "\n",
        "    Args:\n",
        "        title (str): Title of plot\n",
        "      \n",
        "\n",
        "  label (str): x-axis label\n",
        "        train_results (list): Results vector of training of length of number\n",
        "            of epochs trained. Could be loss or accuracy.\n",
        "        val_results (list): Results vector of validation of length of number\n",
        "            of epochs. Could be loss or accuracy.\n",
        "        yscale (str, optional): Matplotlib.pyplot.yscale parameter. \n",
        "            Defaults to 'linear'.\n",
        "        save_path (str, optional): If passed, figure will be saved at this path.\n",
        "            Defaults to None.\n",
        "        extra_pt (tuple, optional): Tuple of length 2, defining x and y coordinate\n",
        "            of where an additional black dot will be plotted. Defaults to None.\n",
        "        extra_pt_label (str, optional): Legend label of extra point. Defaults to None.\n",
        "    \"\"\"\n",
        "    \n",
        "    epoch_array = np.arange(len(train_results)) + 1\n",
        "    train_label, val_label = \"Training \"+label.lower(), \"Validation \"+label.lower()\n",
        "    \n",
        "    sns.set(style='ticks')\n",
        "\n",
        "    plt.plot(epoch_array, train_results, epoch_array, val_results, linestyle='dashed', marker='o', zorder=-1)\n",
        "    legend = ['Train results', 'Validation results']\n",
        "    \n",
        "    if extra_pt:\n",
        "        ####################\n",
        "        ## YOUR CODE HERE ##\n",
        "        ####################\n",
        "        plt.scatter(extra_pt[0], extra_pt[1], c=\"k\")\n",
        "        legend = ['Train results', 'Validation results', extra_pt_label]\n",
        "\n",
        "        # END OF YOUR CODE #\n",
        "        \n",
        "    plt.legend(legend)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(label)\n",
        "    plt.yscale(yscale)\n",
        "    plt.title(title)\n",
        "    \n",
        "    # sns.despine(trim=True, offset=5)\n",
        "    plt.title(title, fontsize=15)\n",
        "    if save_path:\n",
        "        plt.savefig(str(save_path), bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def empty_loss(*irgendwas):\n",
        "    return torch.tensor(0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EXv7vzLvXghr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss = run_training(model=model, optimizer=optimizer, loss_fn=loss_fn, device=device, num_epochs=10,\n",
        "                                    train_dataloader=train_dataloader, val_dataloader=val_dataloader, verbose=True)"
      ],
      "metadata": {
        "id": "WLE_PzsPaVyx",
        "outputId": "7bc8aac2-9602-4e20-c076-451281e14440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='9' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      90.00% [9/10 02:12<00:14]\n",
              "    </div>\n",
              "    \n",
              "Train loss: 2.73, val loss: 0.92<p>Train loss: 0.46, val loss: 1.45<p>Train loss: 0.41, val loss: 2.71<p>Train loss: 0.39, val loss: 22.49<p>Train loss: 0.39, val loss: 2.41<p>Train loss: 0.44, val loss: 4.08<p>Train loss: 0.46, val loss: 3.46<p>Train loss: 0.42, val loss: 1.79<p>Train loss: 0.38, val loss: 1.38<p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/44 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: tensor([2.9515, 3.7098, 2.7703, 4.2154, 3.4698, 3.5226, 3.6549, 3.7402, 4.2778,\n",
            "        4.1894, 4.8434, 3.5047], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([3.0442, 4.5344, 3.7126, 3.8722, 3.8932, 3.2521, 3.6996, 3.7578, 4.9769,\n",
            "        4.4846, 5.1432, 4.0136], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([3.2304, 3.5086, 3.9498, 4.3846, 3.9600, 4.4119, 5.0767, 3.4863, 4.1335,\n",
            "        4.1602, 3.8298, 3.3778], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([3.9753, 4.4451, 3.4464, 3.3807, 3.7374, 4.4463, 3.9749, 5.5500, 4.6017,\n",
            "        5.5378, 4.2920, 3.1454], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([2.5932, 4.2049, 4.1472, 2.7506, 4.2102, 3.8155, 3.7398, 3.8338, 3.6594,\n",
            "        4.0032, 4.1407, 3.5378], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([3.1546, 3.4179, 5.0919, 3.3063, 4.3785, 4.1886, 3.6824, 3.9523, 4.0645,\n",
            "        5.9869, 3.9886, 3.2487], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([2.7830, 3.8574, 3.4093, 3.9135, 3.8301, 4.7912, 3.6933, 4.4524, 4.6407,\n",
            "        4.0593, 3.3399, 3.5826], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([4.0426, 3.8329, 3.9959, 3.8834, 2.9747, 4.6588, 4.0889, 2.9469, 5.3435,\n",
            "        4.0077, 4.6638, 4.1581], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n",
            "prediction: tensor([2.6635, 4.6307, 2.9038, 3.8914, 3.6848, 3.7700, 4.1205, 4.0121, 5.7719,\n",
            "        5.3021, 4.6183, 4.9136], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
            "target: tensor([3.4045, 4.0622, 4.3833, 3.8089, 3.7160, 4.5961, 3.9722, 3.9338, 4.8371,\n",
            "        4.8683, 4.4438, 4.1604], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-20c6ee4c5b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loss, val_loss = run_training(model=model, optimizer=optimizer, loss_fn=loss_fn, device=device, num_epochs=10,\n\u001b[0;32m----> 2\u001b[0;31m                                     train_dataloader=train_dataloader, val_dataloader=val_dataloader, verbose=True)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-f03f0bce3174>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, loss_fn, device, num_epochs, train_dataloader, val_dataloader, verbose)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m#Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mepoch_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-f03f0bce3174>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, optimizer, model, loss_fn, device, master_bar, scaler)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfastprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastprogress/fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/airbnb_price/feature_extraction/feature_extraction_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpicture_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}