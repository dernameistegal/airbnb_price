{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dernameistegal/airbnb_price/blob/main/text_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol6-Fgcp2DgQ"
      },
      "source": [
        "# Exercise Sheet 6 – Natural Language Processing with BERT\n",
        "\n",
        "* Deep Learning\n",
        " * Instructor: Alexander Ecker\n",
        " * Tutors: Max Burg, Laura Pede\n",
        " * Due date: **Tue, Feb 1, noon**\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVlgjZoP11i8"
      },
      "source": [
        "### IMPORTANT SUBMISSION INSTRUCTIONS\n",
        "\n",
        "- When you're done, download the notebook and rename it to \\<surname1\\>_\\<surname2\\>_\\<surname3\\>.ipynb\n",
        "- Only submit the ipynb file, no other file is required\n",
        "- Submit only once\n",
        "- The deadline is strict\n",
        "- You are required to present your solution in the tutorial; submission of the notebook alone is not sufficient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3AbiATnjlaO"
      },
      "source": [
        "## Useful information: lecture schedule and exercise sheet deadline\n",
        "\n",
        "The topics you will need to solve in this exercise sheet may not have been discussed in the lecture at the time we handed out this notebook. We kept the exercises rather short so you can solve them in one week and recommend that you wait until all topics have been introduced in the lecture. If you want to start right away, here are some resources that might be helpful:\n",
        "\n",
        "- https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
        "- https://jalammar.github.io/illustrated-transformer/\n",
        "- https://jalammar.github.io/illustrated-bert/\n",
        "- https://huggingface.co/transformers/glossary.html (Glossary)\n",
        "\n",
        "The articles that are linked in those blog posts are nice resources on background information as well.\n",
        "\n",
        "(Figures and some explanaitions are based on the work of Jay Alammar, jalammar.github.io)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0LCu5AP16--"
      },
      "source": [
        "# Setup and Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Le0E49B2Ubn"
      },
      "source": [
        "## Using Colab GPU for Training \n",
        "\n",
        "A GPU can be added by going to the menu and selecting \n",
        "\n",
        "\n",
        "```\n",
        "Edit --> Notebook Settings --> Hardware accelerator --> (GPU)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kfgQWzyZS3zN",
        "outputId": "6a8d7260-7194-4e05-b934-565324676c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n",
            "There is/are 1 GPU(s) available.\n",
            "\n",
            "We will use the GPU:  Tesla P100-PCIE-16GB\n",
            "with the following properties: \n",
            "_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There is/are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print()\n",
        "    print(\"We will use the GPU: \", torch.cuda.get_device_name(0))\n",
        "    print(\"with the following properties: \")\n",
        "    print(torch.cuda.get_device_properties(0))\n",
        "else:\n",
        "    print('No GPU available, training on CPU instead.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UwkbgUn2fnn"
      },
      "source": [
        "## Installing the Hugging Face library \n",
        "\n",
        " Next, let’s install the [transformers package from the Hugging Face library](https://huggingface.co/transformers/index.html) which will give us a Pytorch interface for working with implementations of state-of-the-art embedding layers. This library contains interfaces for  pretrained language models like BERT, XLNet, OpenAI’s GPT.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hOrc3Hf6213A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu-hKzYgFvZJ"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "it5JOetS6sgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d78582c-ed15-4b38-a60e-5810e08ca6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import fastprogress\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDiG-AxX6tQd"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kXM_-H-m7B-B"
      },
      "outputs": [],
      "source": [
        "# load the training data\n",
        "file_name = \"/content/drive/MyDrive/Colab/airbnb/data/listings_workfile.pickle\"\n",
        "data = pd.read_pickle(file_name)\n",
        "reviews, labels = data['description_en'].to_numpy(), data['log_price'].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqjAI7Uiz-ah"
      },
      "source": [
        "### Explore the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SyuJr8Io0DhW",
        "outputId": "196ca9de-335a-4eba-cd43-859196342623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d1e0dff-c2b3-485d-946f-925975850dc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.56435</td>\n",
              "      <td>The Appartment Lainz is a beautiful apartment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.2485</td>\n",
              "      <td>A beautiful and modern room in the middle of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.12713</td>\n",
              "      <td>A nice and modern room in the middle of the fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.78749</td>\n",
              "      <td>The apartment is about 97sqm large and has an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.17439</td>\n",
              "      <td>In the beautiful classic Viennese old building...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.15888</td>\n",
              "      <td>A beautiful, modern apartment in the green dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.2485</td>\n",
              "      <td>It's all within walking distance: Naschmarkt, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.71357</td>\n",
              "      <td>Only suitable for one person (single bed)&lt;br /...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.13549</td>\n",
              "      <td>The accommodation is a room in a large apartme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.46574</td>\n",
              "      <td>Completely furnished, bright and comfy 64sqm a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d1e0dff-c2b3-485d-946f-925975850dc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d1e0dff-c2b3-485d-946f-925975850dc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d1e0dff-c2b3-485d-946f-925975850dc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0                                                  1\n",
              "0  4.56435  The Appartment Lainz is a beautiful apartment ...\n",
              "1   4.2485  A beautiful and modern room in the middle of t...\n",
              "2  4.12713  A nice and modern room in the middle of the fa...\n",
              "3  4.78749  The apartment is about 97sqm large and has an ...\n",
              "4  4.17439  In the beautiful classic Viennese old building...\n",
              "5  4.15888  A beautiful, modern apartment in the green dis...\n",
              "6   4.2485  It's all within walking distance: Naschmarkt, ...\n",
              "7  3.71357  Only suitable for one person (single bed)<br /...\n",
              "8  3.13549  The accommodation is a room in a large apartme...\n",
              "9  3.46574  Completely furnished, bright and comfy 64sqm a..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO show the first 10 samples together\n",
        "# with their label (positive or negative review)\n",
        "import pandas as pd\n",
        "pd.DataFrame(np.hstack([labels[0:10].reshape(10,1), reviews[0:10].reshape(10,1)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zE3O85czz6-y",
        "outputId": "526c1630-ebe7-4ab9-c93d-759758b37653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO Visualize the length of the reviews in your dataset\n",
        "def count_words(string):\n",
        "    return len(string.split())\n",
        "\n",
        "review_lengths = np.vectorize(count_words)(reviews)\n",
        "\n",
        "a = plt.hist(review_lengths, bins = 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5OyMQPFfKQ"
      },
      "source": [
        "## BERT: tokenization & input formatting\n",
        "\n",
        "We will use the excellent [transformers package from the Hugging Face library](https://huggingface.co/transformers/index.html) to work with BERT.\n",
        "\n",
        "The first step is to tokenize the reviews and bring them into the format that BERT expects. This includes\n",
        "\n",
        "- Tokenization: break words up into words and subwords in the format BERT was trained with\n",
        "- Adding special tokens: [CLS], [SEP]\n",
        "- Trimming sentences to maximum length\n",
        "- Padding [PAD] shorter sentences. We want BERT to process our examples batch-wise. Hence, we need to pad all lists to the same size, so we can represent the input as one 2-d array.\n",
        "\n",
        "Documentation of `BertTokenizer`: https://huggingface.co/transformers/model_doc/bert.html#berttokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eZTmDwOueqEN",
        "outputId": "27489196-c674-4a9a-abf7-21e246431528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Loading the BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# Get rid of Colab warning about Tensorflow versions\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading the BERT tokenizer...')\n",
        "\n",
        "# We will use bert-base-uncased model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EM0eJoNaKFXb",
        "outputId": "5d9bcfaf-0a8f-4800-baaf-93cd0d6f1b3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11404/11404 [00:49<00:00, 229.23it/s]\n"
          ]
        }
      ],
      "source": [
        "# Maximum length of a sequence\n",
        "MAX_LEN = 256\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for review in tqdm(reviews):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad to maximum length if the sequence is shorter\n",
        "    sequence = tokenizer.encode_plus(\n",
        "                    review,                      # Review to encode.\n",
        "                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                    truncation=True,\n",
        "                    max_length=MAX_LEN,\n",
        "                    padding='max_length',\n",
        "                    return_attention_mask=True)\n",
        "    input_ids.append(sequence['input_ids'])\n",
        "    attention_masks.append(sequence['attention_mask'])\n",
        "\n",
        "input_ids = np.array(input_ids)\n",
        "attention_masks = np.array(attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D9P8lwIiMHLv",
        "outputId": "5cfbf0da-c8e9-4d5c-e9b2-ad44df9be6d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My accommodation is 10 minute walk from the U1 station Reumannplatz, bus stop almost right in front of the door, midway in the 10th district with the new central station. It is very well laid out, with private street access and especially equipped with some facilities for SM games, such as cage, cells, Andreaskreuz, bottle train, Sling,... <br />A bedroom with desk, kitchen, anteroom, bathroom and then living-playroom with sofa bed, the cell offers another 5th sleeping place.\n",
            "[  101  2026 11366  2003  2184  3371  3328  2013  1996  1057  2487  2276\n",
            "  2128 19042 16275 20051  2480  1010  3902  2644  2471  2157  1999  2392\n",
            "  1997  1996  2341  1010 12213  1999  1996  6049  2212  2007  1996  2047\n",
            "  2430  2276  1012  2009  2003  2200  2092  4201  2041  1010  2007  2797\n",
            "  2395  3229  1998  2926  6055  2007  2070  4128  2005 15488  2399  1010\n",
            "  2107  2004  7980  1010  4442  1010 12460 21638 13765  2480  1010  5835\n",
            "  3345  1010 27076  1010  1012  1012  1012  1026  7987  1013  1028  1037\n",
            "  5010  2007  4624  1010  3829  1010 14405 10624  5358  1010  5723  1998\n",
            "  2059  2542  1011  2377  9954  2007 10682  2793  1010  1996  3526  4107\n",
            "  2178  4833  5777  2173  1012   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[CLS] my accommodation is 10 minute walk from the u1 station reumannplatz, bus stop almost right in front of the door, midway in the 10th district with the new central station. it is very well laid out, with private street access and especially equipped with some facilities for sm games, such as cage, cells, andreaskreuz, bottle train, sling,... < br / > a bedroom with desk, kitchen, anteroom, bathroom and then living - playroom with sofa bed, the cell offers another 5th sleeping place. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] my accommodation is 10 minute walk from the u1 station reumannplatz, bus stop almost right in front of the door, midway in the 10th district with the new central station. it is very well laid out, with private street access and especially equipped with some facilities for sm games, such as cage, cells, andreaskreuz, bottle train, sling,... < br / > a bedroom with desk, kitchen, anteroom, bathroom and then living - playroom with sofa bed, the cell offers another 5th sleeping place. [SEP]\n"
          ]
        }
      ],
      "source": [
        "from re import T\n",
        "# TODO\n",
        "# Print the 25th (index 24 as indexing starts with 0 in python) example sentence\n",
        "# 1) as original, \n",
        "print(reviews[24])\n",
        "# 2) list of token IDs, \n",
        "print(input_ids[24])\n",
        "# 3) it's attention mask,\n",
        "print(attention_masks[24])\n",
        "# 4) the human readable string recreated from the token IDs, and\n",
        "print(tokenizer.decode(input_ids[24]))\n",
        "# 5) the human readable, recreated string with its according attention mask applied\n",
        "print(tokenizer.decode(input_ids[24][attention_masks[24].astype(\"bool\")]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qQYZFU0VXhI"
      },
      "source": [
        "## Training, Validation, Test Split\n",
        "\n",
        "Use 10% of the dataset as validation and test set, respectively. Use the other 80% for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3E58xzigaBA_"
      },
      "outputs": [],
      "source": [
        "# TODO: Split data into training, validation, and test data\n",
        "# (features, labels, and attention masks)\n",
        "tmp = train_test_split(input_ids, labels, attention_masks, train_size=0.8, random_state=42)\n",
        "ids_train, ids_val, labels_train, labels_val, masks_train, masks_val = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "28WNp-yV85Xo",
        "outputId": "c605faf1-d8f9-4011-ab4b-2ed7d93c241d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9123, 256)\n",
            "(2281, 256)\n",
            "(9123,)\n",
            "(2281,)\n",
            "(9123, 256)\n",
            "(2281, 256)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Print out the shapes of your splitted train, validation, and test set\n",
        "# Hint: your validation set should contain 500 samples. How many tokens are\n",
        "# included per sample? \n",
        "\n",
        "# (1) print the feature shapes\n",
        "print(ids_train.shape)\n",
        "print(ids_val.shape)\n",
        "\n",
        "# (2) print the label shapes\n",
        "print(labels_train.shape)\n",
        "print(labels_val.shape)\n",
        "\n",
        "# (3) print the attention mask shapes\n",
        "print(masks_train.shape)\n",
        "print(masks_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaSTkvQca3or"
      },
      "source": [
        "## Create DataLoader\n",
        "\n",
        "You can use `TensorDataset`, `torch.from_numpy(...)`, and `DataLoader(...)` to create Dataloaders for your dataset holding features, labels and attention masks. Make sure to shuffle your training data. Is shuffling required for the validation and test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7my-m1Zt75Zp"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# create dataloaders\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "trainset = TensorDataset(torch.from_numpy(ids_train), torch.from_numpy(labels_train), torch.from_numpy(masks_train))\n",
        "valset = TensorDataset(torch.from_numpy(ids_val), torch.from_numpy(labels_val), torch.from_numpy(masks_val))\n",
        "\n",
        "b = 128\n",
        "trainloader = DataLoader(trainset, shuffle=True, num_workers=2, batch_size=b)\n",
        "valloader = DataLoader(valset, shuffle=False, num_workers=2, batch_size=b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vuwkaCRkYLL"
      },
      "source": [
        "\n",
        "# Sentiment analysis - classification model\n",
        "\n",
        "We will build a sentiment classifier estimating if a review is positive or negative by using transfer learning from a pre-trained BERT model, adding a readout network to BERT's sentence embeddings. For that task, we do not use the whole sentence embedding space, but only the subspace corresponding to the classification (`[CLS]`) token, including all of the 768 hidden units.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeJdGstbetUX"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "#### TODO\n",
        "\n",
        "\n",
        "- Load a pre-trained BERT model. A good starting point for more information is the quickstart guide of the transformers library: https://huggingface.co/transformers/quickstart.html . \n",
        "- Make sure to implement the possibility to use attention masks as well. \n",
        "- Slice BERT's sentence embedding space as described above (we only want to use the `[CLS]` token for classification)\n",
        "- Add two fully connected layers to that sentence embedding subspace. \n",
        "  - The first fully connected layer should have 768 output units, followed by ReLU activation function. \n",
        "  - The second (and last) fully connected layer acts as a binary classifier on top, mapping a `(BATCH_SIZE x 768)` tensor onto `(BATCH_SIZE, 2)` to predict the two classes, encoded by a one-hot vector.\n",
        "\n",
        "\n",
        "*Hints:*\n",
        "- Note that we used the `'bert-base-uncased'` model in the tokenizer. Use the same model here. For more information, check https://huggingface.co/transformers/pretrained_models.html\n",
        "- Loading the BERT model with pre-trained model weights: \n",
        "  - https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.from_pretrained\n",
        "  - https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "- More information on attention masks:\n",
        "  - https://huggingface.co/transformers/glossary.html#attention-mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UqgDnbrl_gny"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, fine_tune=False, with_attention_masks=True, cls_dropout_prob=0):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "\n",
        "        self.with_attention_masks = with_attention_masks\n",
        "\n",
        "        # TODO: BertModel as an embedding layer\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\", output_attentions=True)\n",
        "\n",
        "        # Turn gradients for BertModel on/off\n",
        "        # (Fine-tuning is an optional task at the end of this exercise sheet)\n",
        "        self.bert.requires_grad_(fine_tune)\n",
        "\n",
        "        # TODO: Classification layer\n",
        "        self.linear1 = nn.Linear(768, 768)\n",
        "        self.linear2 = nn.Linear(768, 1)\n",
        "        self.drop1 = nn.Dropout(cls_dropout_prob)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        if not self.with_attention_masks:\n",
        "            attention_mask = None\n",
        "        result = self.bert(input_ids, attention_mask)\n",
        "        embedding = result[\"last_hidden_state\"][:, 0, :]\n",
        "        embedding = self.drop1(embedding)\n",
        "        attentions = result[\"attentions\"]\n",
        "        x = F.relu(self.linear1(embedding))\n",
        "        x = self.linear2(x)\n",
        "        return x, attentions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOT3lpt2PQNp"
      },
      "source": [
        "## Instantiate two models\n",
        "\n",
        "One model should use attention masks, the other should not. Initialize the models' `with_attention_mask` attribute accordingly, so you can discriminate between the two model types in your training and validation function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTERZi4LkdJe"
      },
      "source": [
        "## Training and Testing\n",
        "\n",
        "#### TODO\n",
        "\n",
        "- Train both models. We recommend using the Adam optimizer. \n",
        "- To monitor model training, output training and validation loss and accuracy in regular intervals, at least after each epoch. Also, plot the training and validation loss and accuracy vs. epochs for both models after training.\n",
        "\n",
        "*Hints:*\n",
        "\n",
        "- Here, we have a classification problem with 2 classes. In our course, you solved classification problems before. Which loss function is appropriate in such a setting? \n",
        "- Using a batch size of 128 and training for 5 epochs, we achieved roughly 80% accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ipI-UlSskm13",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title train utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import fastprogress\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "def train(dataloader, optimizer, model, loss_fn, device, master_bar):\n",
        "    \"\"\"Run one training epoch.\"\"\"\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_rmse = 0\n",
        "\n",
        "    for ids, labels, masks in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "        ids, labels, masks = ids.to(device), labels.to(device).float(), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        model.train()\n",
        "\n",
        "        # Forward pass\n",
        "        labels_pred = model(ids, masks)[0]\n",
        "        labels_pred = torch.squeeze(labels_pred)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = loss_fn(labels_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # For plotting the train loss, save it for each sample\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "    # Return the mean loss and the accuracy of this epoch\n",
        "    return np.mean(epoch_loss), np.sqrt(np.mean(epoch_loss))\n",
        "\n",
        "\n",
        "def validate(dataloader, model, loss_fn, device, master_bar):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_rmse = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for ids, labels, masks in fastprogress.progress_bar(dataloader, parent=master_bar):\n",
        "            ids, labels, masks = ids.to(device), labels.to(device).float(), masks.to(device)\n",
        "\n",
        "            # make a prediction on validation set\n",
        "            labels_pred = model(ids, masks)[0]\n",
        "            labels_pred = torch.squeeze(labels_pred)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fn(labels_pred, labels)\n",
        "\n",
        "            # For plotting the train loss, save it for each sample\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "    return np.mean(epoch_loss), np.sqrt(np.mean(epoch_loss))\n",
        "                \n",
        "\n",
        "def run_training(model, optimizer, loss_function, device, num_epochs, \n",
        "                train_dataloader, val_dataloader, verbose=False):\n",
        "\n",
        "    start_time = time.time()\n",
        "    master_bar = fastprogress.master_bar(range(num_epochs))\n",
        "    train_losses, val_losses, train_accs, val_accs = [],[],[],[]\n",
        "    for epoch in master_bar:\n",
        "        # Train the model\n",
        "        epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model, \n",
        "                                                  loss_function, device, master_bar)\n",
        "        # Validate the model\n",
        "        epoch_val_loss, epoch_val_acc = validate(val_dataloader, model, loss_function, device, master_bar)\n",
        "\n",
        "        # Save loss and acc for plotting and add increase of val_acc\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        train_accs.append(epoch_train_acc)\n",
        "        val_accs.append(epoch_val_acc)\n",
        "        \n",
        "        if verbose:\n",
        "            master_bar.write(f'Train loss: {epoch_train_loss:.2f}, val loss: {epoch_val_loss:.2f}, train rmse: {epoch_train_acc:.3f}, val rmse {epoch_val_acc:.3f}')\n",
        "        \n",
        "\n",
        "    time_elapsed = np.round(time.time() - start_time, 0).astype(int)\n",
        "    print(f'Finished training after {time_elapsed} seconds.')\n",
        "    return train_losses, val_losses, train_accs, val_accs\n",
        "\n",
        "\n",
        "def plot(title, label, train_results, val_results, yscale='linear', save_path=None, \n",
        "         extra_pt=None, extra_pt_label=None):\n",
        "    \"\"\"Plot learning curves.\n",
        "    Args:\n",
        "        title (str): Title of plot\n",
        "      \n",
        "  label (str): x-axis label\n",
        "        train_results (list): Results vector of training of length of number\n",
        "            of epochs trained. Could be loss or accuracy.\n",
        "        val_results (list): Results vector of validation of length of number\n",
        "            of epochs. Could be loss or accuracy.\n",
        "        yscale (str, optional): Matplotlib.pyplot.yscale parameter. \n",
        "            Defaults to 'linear'.\n",
        "        save_path (str, optional): If passed, figure will be saved at this path.\n",
        "            Defaults to None.\n",
        "        extra_pt (tuple, optional): Tuple of length 2, defining x and y coordinate\n",
        "            of where an additional black dot will be plotted. Defaults to None.\n",
        "        extra_pt_label (str, optional): Legend label of extra point. Defaults to None.\n",
        "    \"\"\"\n",
        "    \n",
        "    epoch_array = np.arange(len(train_results)) + 1\n",
        "    train_label, val_label = \"Training \"+label.lower(), \"Validation \"+label.lower()\n",
        "    \n",
        "    sns.set(style='ticks')\n",
        "\n",
        "    plt.plot(epoch_array, train_results, epoch_array, val_results, linestyle='dashed', marker='o', zorder=-1)\n",
        "    legend = ['Train results', 'Validation results']\n",
        "    \n",
        "    if extra_pt:\n",
        "        ####################\n",
        "        ## YOUR CODE HERE ##\n",
        "        ####################\n",
        "        plt.scatter(extra_pt[0], extra_pt[1], c=\"k\")\n",
        "        legend = ['Train results', 'Validation results', extra_pt_label]\n",
        "\n",
        "        # END OF YOUR CODE #\n",
        "        \n",
        "    plt.legend(legend)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(label)\n",
        "    plt.yscale(yscale)\n",
        "    plt.title(title)\n",
        "    \n",
        "    # sns.despine(trim=True, offset=5)\n",
        "    plt.title(title, fontsize=15)\n",
        "    if save_path:\n",
        "        plt.savefig(str(save_path), bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Instantiate the models\n",
        "model1 = SentimentClassifier(fine_tune=False, with_attention_masks=True)\n",
        "model1 = model1.to(device)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=1e-4)\n",
        "result = run_training(model1, optimizer, loss_fn, device, 10, trainloader, valloader, verbose=True)"
      ],
      "metadata": {
        "id": "nXfkQU-21cI3",
        "outputId": "da2f97f7-f250-4b72-b98e-2c1351f4d08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      10.00% [1/10 01:38<14:45]\n",
              "    </div>\n",
              "    \n",
              "Train loss: 1.03, val loss: 0.39, train rmse: 1.014, val rmse 0.625<p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='14' class='' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      4.90% [14/286 00:03<01:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0b5d633b3c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-ea0d4c1a4586>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, loss_function, device, num_epochs, train_dataloader, val_dataloader, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         epoch_train_loss, epoch_train_acc = train(train_dataloader, optimizer, model, \n\u001b[0;32m---> 76\u001b[0;31m                                                   loss_function, device, master_bar)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Validate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mepoch_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-ea0d4c1a4586>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, optimizer, model, loss_fn, device, master_bar)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# For plotting the train loss, save it for each sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Return the mean loss and the accuracy of this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5O1pi6tQBl"
      },
      "source": [
        "## Inference testing\n",
        "\n",
        "This section consists of testing the models using inference testing, i.e., in our case, using other reviews to categorize them as positive or negative. \n",
        "\n",
        "#### TODO \n",
        "- Create a function that predicts if a text review is positive or negative\n",
        "-  Choose any of your preferred movies, find a review (e.g. from imdb.com) and compare your model result against the source rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lZLcwRs6tVdV"
      },
      "outputs": [],
      "source": [
        "def pipeline(text, model):\n",
        "    model.eval()\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    MAX_LEN = 256\n",
        "    \n",
        "    sequence = tokenizer.encode_plus(\n",
        "                text,                      # Review to encode.\n",
        "                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                truncation=True,\n",
        "                max_length=MAX_LEN,\n",
        "                padding='max_length',\n",
        "                return_attention_mask=True)\n",
        "    tokens = torch.tensor(sequence['input_ids']).to(device).reshape(1,256)\n",
        "    attention_mask = torch.tensor(sequence['attention_mask']).to(device).reshape(1, 256)\n",
        "    with torch.no_grad():\n",
        "        output = model(tokens, attention_mask)\n",
        "        price = torch.exp(output[0]).item()\n",
        "        attention = output[1]\n",
        "    print(price)\n",
        "    return attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "BSDQ3xG_uWFw",
        "outputId": "d5a0cbbc-4688-4566-fa90-e64b425b13ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.217312812805176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# TODO\n",
        "  \n",
        "test_review = \"\"\"\n",
        "\"\"\"\n",
        "\n",
        "attentions = pipeline(test_review, model1)\n",
        "\n",
        "len(attentions)\n",
        "attentions[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWb3P4SWUD3C"
      },
      "source": [
        "## [Optional] Fine-tune BERT model\n",
        "\n",
        "(This is a non-mandatory, fully optional task)\n",
        "\n",
        "Can you improve performance by fine-tuning BERT in addition to training the readout classifier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz4a6UXE1esI",
        "outputId": "3fb9660c-ebd6-4564-baba-fba27e5bfee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='8' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      40.00% [8/20 32:10<48:15]\n",
              "    </div>\n",
              "    \n",
              "Train loss: 1.64, val loss: 0.49, train rmse: 1.280, val rmse 0.699<p>Train loss: 0.42, val loss: 0.42, train rmse: 0.651, val rmse 0.646<p>Train loss: 0.34, val loss: 0.33, train rmse: 0.586, val rmse 0.576<p>Train loss: 0.31, val loss: 0.43, train rmse: 0.560, val rmse 0.655<p>Train loss: 0.28, val loss: 0.23, train rmse: 0.526, val rmse 0.484<p>Train loss: 0.24, val loss: 0.29, train rmse: 0.494, val rmse 0.542<p>Train loss: 0.22, val loss: 0.30, train rmse: 0.472, val rmse 0.545<p>Train loss: 0.20, val loss: 0.27, train rmse: 0.442, val rmse 0.517<p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='227' class='' max='286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      79.37% [227/286 02:57<00:46]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Instantiate the models\n",
        "b = 32\n",
        "trainloader = DataLoader(trainset, shuffle=True, num_workers=2, batch_size=b)\n",
        "valloader = DataLoader(valset, shuffle=False, num_workers=2, batch_size=b)\n",
        "model2 = SentimentClassifier(fine_tune=True, with_attention_masks=True, cls_dropout_prob=0.5)\n",
        "model2 = model2.to(device)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-5)\n",
        "result = run_training(model2, optimizer, loss_fn, device, 20, trainloader, valloader, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iaTaTq66twuP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Ex6_2021.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}